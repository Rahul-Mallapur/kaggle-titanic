{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn import svm, linear_model, datasets, neighbors\n",
    "from patsy import dmatrices\n",
    "import random\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import sklearn.ensemble as ske"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#importing train data \n",
    "\n",
    "#Formatted the surnames and tickets\n",
    "#surnames: using the surnames, grouped people. Used the grouping for the formula\n",
    "#tickets: removed the non-albhabet-numermic characters and used the first 3characters for the formula\n",
    "\n",
    "df = pd.read_csv(\"data/train.csv\")\n",
    "df = df.drop(['Ticket', 'Cabin', 'Name', 'Surname', 'S_Ticket'], axis = 1)\n",
    "df = df.dropna()\n",
    "\n",
    "#ToDos\n",
    "#(a) have a single boolean variable for relatives on the ship\n",
    "#(b) age need not be a continuous variable, we could combine them as child, male, female (child < 16, has greater chance of survival)\n",
    "#(c) need to take care of the missing values (drop, replace with frequently occuring, mean)\n",
    "#(d) Fare variable is already correlated with Class, Embarked variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#shuffling the data\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "#using dmatrices to get data for the ml algorithms\n",
    "formula = 'Survived ~ C(Pclass) + C(Sex)+ Age + SibSp + Parch + Fare + Surname_In + Ticket_In + C(Embarked)'\n",
    "y,x = dmatrices(formula, data=df, return_type='dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#cross validation within the train data\n",
    "n_train = int(0.15*len(y))\n",
    "x_train = x[n_train:]\n",
    "y_train = y[n_train:]\n",
    "\n",
    "x_test = x[:n_train]\n",
    "y_test = y[:n_train]\n",
    "\n",
    "y_train = np.asarray(y_train).ravel()\n",
    "y_test = np.asarray(y_test).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "acc_sum = 0\n",
    "logistic = linear_model.LogisticRegression(C = 1, max_iter = 200, tol = 1e-5, class_weight = {1: 1})\n",
    "for i in range(5):\n",
    "    acc_sum += logistic.fit(x_train, y_train).score(x_test, y_test)\n",
    "accuracy_LR = acc_sum/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#KNN\n",
    "kneighbors = neighbors.KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=60)\n",
    "\n",
    "acc_sum = 0\n",
    "logistic = linear_model.LogisticRegression(C = 1, max_iter = 200, tol = 1e-5, class_weight = {1: 1})\n",
    "for i in range(5):\n",
    "    acc_sum += kneighbors.fit(x_train, y_train).score(x_test, y_test)\n",
    "accuracy_KNN = acc_sum/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#NeuralNets\n",
    "acc_sum = 0\n",
    "neural_classifier = MLPClassifier(max_iter = 300)\n",
    "\n",
    "for i in range(5):\n",
    "    acc_sum += neural_classifier.fit(x_train, y_train).score(x_test, y_test)\n",
    "accuracy_NN = acc_sum/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "acc_sum = 0\n",
    "for i in range(5):\n",
    "    acc_sum += ske.RandomForestClassifier(n_estimators=100).fit(x_train, y_train).score(x_test, y_test)\n",
    "accuracy_RF = acc_sum/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#SVM\n",
    "y_svm,x_svm = dmatrices(formula, data=df, return_type='matrix')\n",
    "#need to experiment with different features\n",
    "#'Intercept' (column 0), 'C(Pclass)' (columns 1:3), 'C(Sex)' (column 3), 'C(Embarked)' (columns 4:6)\n",
    "#'Age' (column 6), 'SibSp' (column 7), 'Parch' (column 8), 'Fare' (column 9)\n",
    "\n",
    "feature_1 = 3\n",
    "feature_2 = 2\n",
    "\n",
    "x_svm = np.asarray(x_svm)\n",
    "x_svm = x_svm[:,[feature_1, feature_2]]  \n",
    "\n",
    "y_svm = np.asarray(y_svm)\n",
    "y_svm = y_svm.flatten()\n",
    "\n",
    "#cross validation within the train data\n",
    "n_train = int(0.15*len(y))\n",
    "x_svm_train = x_svm[n_train:]\n",
    "y_svm_train = y_svm[n_train:]\n",
    "\n",
    "x_svm_test = x_svm[:n_train]\n",
    "y_svm_test = y_svm[:n_train]\n",
    "\n",
    "# create a list of the types of kernels we will use for your analysis\n",
    "\n",
    "accuracy_SVM_linear = svm.SVC(kernel='linear', C = 2).fit(x_svm_train, y_svm_train).score(x_svm_test, y_svm_test)\n",
    "accuracy_SVM_rbf = svm.SVC(kernel='rbf', gamma=3).fit(x_svm_train, y_svm_train).score(x_svm_test, y_svm_test)\n",
    "accuracy_SVM_poly = svm.SVC(kernel='poly', gamma=2).fit(x_svm_train, y_svm_train).score(x_svm_test, y_svm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:  0.745283018868\n",
      "K Nearest Neighbors:  0.660377358491\n",
      "Neural Nets:  0.660377358491\n",
      "Random Forest:  0.807547169811\n",
      "SVM -  (a)linear:  0.764150943396 , (b)rbf:  0.764150943396 , (c)poly:  0.764150943396\n"
     ]
    }
   ],
   "source": [
    "#Print and compare the results\n",
    "print(\"Logistic Regression: \", accuracy_LR)\n",
    "print(\"K Nearest Neighbors: \", accuracy_KNN)\n",
    "print(\"Neural Nets: \", accuracy_NN)\n",
    "print(\"Random Forest: \", accuracy_RF)\n",
    "print(\"SVM - \", \"(a)linear: \", accuracy_SVM_linear, \", (b)rbf: \", accuracy_SVM_rbf, \", (c)poly: \", accuracy_SVM_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rahulmallapur/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#Building formal models\n",
    "df_predict = pd.read_csv(\"data/test.csv\")\n",
    "df_predict['Survived'] = 1\n",
    "df_predict = df_predict.drop(['Ticket', 'Cabin', 'Name','Surname', 'S_Ticket'], axis = 1)\n",
    "df_predict = df_predict.sample(frac=1).reset_index(drop=True)\n",
    "df_predict = df_predict.fillna(method = 'pad')\n",
    "\n",
    "\n",
    "#training on the best models from above: RNN, SVM(poly), SVM(rbf), LogisticRegression\n",
    "\n",
    "#LogisticRegression\n",
    "y_predict,x_predict = dmatrices(formula, data=df_predict, return_type='dataframe')\n",
    "x_predict\n",
    "logistic = linear_model.LogisticRegression(C = 1, max_iter = 200, tol = 1e-5, class_weight = {1: 1})\n",
    "logistic.fit(x, y)\n",
    "y_predict = logistic.predict(x_predict)\n",
    "np.savetxt(\"prediction_lr.csv\", y_predict.astype(int), delimiter=\",\")\n",
    "\n",
    "\n",
    "#RNN\n",
    "y_predict,x_predict = dmatrices(formula, data=df_predict, return_type='dataframe')\n",
    "\n",
    "y = np.asarray(y).ravel()\n",
    "y_predict = np.asarray(y_predict).ravel()\n",
    "rnn = ske.RandomForestClassifier(n_estimators=100).fit(x, y)\n",
    "y_predict = rnn.predict(x_predict)\n",
    "np.savetxt(\"prediction_rf.csv\", y_predict.astype(int), delimiter=\",\")\n",
    "\n",
    "\n",
    "#SVM\n",
    "y_svm_p,x_svm_p = dmatrices(formula, data=df_predict, return_type='matrix')\n",
    "x_svm_p = np.asarray(x_svm_p)\n",
    "x_svm_p = x_svm_p[:,[feature_1, feature_2]]  \n",
    "\n",
    "y_svm_p = np.asarray(y_svm_p)\n",
    "y_svm_p = y_svm_p.flatten()\n",
    "\n",
    "rbf = svm.SVC(kernel='rbf', gamma=3).fit(x_svm, y_svm)\n",
    "poly = svm.SVC(kernel='poly', gamma=2).fit(x_svm, y_svm)\n",
    "\n",
    "y_rbf = rbf.predict(x_svm_p)\n",
    "y_poly = poly.predict(x_svm_p)\n",
    "\n",
    "np.savetxt(\"prediction_svm_rbf.csv\", y_rbf.astype(int), delimiter=\",\")\n",
    "np.savetxt(\"prediction_svm_poly.csv\", y_poly.astype(int), delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
